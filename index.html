<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AI Vision for Blind using TensorFlow</title>
    <style>
      /* Apple California style with Dark Mode */
      body {
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Roboto",
          "Oxygen", "Ubuntu", "Cantarell", "Fira Sans", "Droid Sans",
          "Helvetica Neue", sans-serif;
        background-color: #1c1c1e;
        color: #e5e5e5;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        align-items: center;
        min-height: 100vh;
        flex-direction: column;
      }

      .container {
        text-align: center;
        padding: 20px;
        background-color: #2c2c2e;
        border-radius: 10px;
        box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3);
        width: 80%;
        max-width: 800px;
      }

      h1 {
        font-size: 2.5rem;
        color: #ffffff;
      }

      .camera-container {
        position: relative;
        width: 640px;
        height: 480px;
        margin: 20px 0;
      }

      video,
      canvas {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        border-radius: 10px;
        box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3);
      }

      button {
        background-color: #007aff;
        color: white;
        border: none;
        padding: 12px 20px;
        border-radius: 8px;
        font-size: 16px;
        cursor: pointer;
        margin-top: 20px;
        transition: background-color 0.3s ease;
      }

      button.green {
        background-color: #4caf50; /* Green when enabled */
      }

      button.red {
        background-color: #e53935; /* Red when disabled */
      }

      button:hover {
        opacity: 0.8;
      }

      .output {
        margin-top: 20px;
        text-align: left;
      }

      ul {
        list-style-type: none;
        padding: 0;
      }

      li {
        padding: 5px 0;
      }

      pre {
        white-space: pre-wrap;
        word-wrap: break-word;
        font-size: 1rem;
        color: #e5e5e5;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <h1>AI Vision for Blind using TensorFlow</h1>

      <div class="camera-container">
        <video id="video" width="640" height="480" autoplay></video>
        <canvas id="objectDetectionCanvas" width="640" height="480"></canvas>
      </div>

      <button id="enableObjectDetection" class="green">
        Disable Object Detection
      </button>
      <button id="enableTextDetection" class="red">
        Enable Text Detection
      </button>

      <div class="output">
        <h3>Detected Objects:</h3>
        <ul id="detectedObjects"></ul>
        <h3>Extracted Text:</h3>
        <pre id="extractedText"></pre>
      </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <script src="https://cdn.jsdelivr.net/npm/tesseract.js"></script>
    <script>
      let model;
      let objectDetectionEnabled = true;
      let textDetectionEnabled = false;
      let currentSpeechQueue = []; // Queue for announcements
      let isSpeaking = false;

      // Load the COCO-SSD model
      cocoSsd
        .load()
        .then((loadedModel) => {
          model = loadedModel;
          console.log("COCO-SSD model loaded successfully.");
          detectObjects();
        })
        .catch((error) => {
          console.error("Error loading COCO-SSD model:", error);
        });

      // Access the device's camera
      const videoElement = document.getElementById("video");
      const objectDetectionCanvas = document.getElementById(
        "objectDetectionCanvas"
      );
      const ctx = objectDetectionCanvas.getContext("2d");

      navigator.mediaDevices
        .getUserMedia({ video: { facingMode: "environment" } })
        .then((stream) => {
          videoElement.srcObject = stream;
          videoElement.play();
          console.log("Camera is ready.");
        })
        .catch((err) => {
          console.error("Error accessing camera:", err);
        });

      function captureFrame() {
        ctx.clearRect(
          0,
          0,
          objectDetectionCanvas.width,
          objectDetectionCanvas.height
        );
        ctx.drawImage(
          videoElement,
          0,
          0,
          objectDetectionCanvas.width,
          objectDetectionCanvas.height
        );
        if (objectDetectionEnabled) {
          detectObjects();
        }
      }

      async function detectObjects() {
        if (model) {
          const predictions = await model.detect(objectDetectionCanvas);
          displayDetectedObjects(predictions);
          drawDetectedBoxes(predictions);
          queueDetectedObjects(predictions);
        }
      }

      function displayDetectedObjects(predictions) {
        const detectedObjectsElement =
          document.getElementById("detectedObjects");
        detectedObjectsElement.innerHTML = "";
        predictions.forEach((prediction) => {
          const li = document.createElement("li");
          li.textContent = `${prediction.class} - ${Math.round(
            prediction.score * 100
          )}%`;
          detectedObjectsElement.appendChild(li);
        });
      }

      function drawDetectedBoxes(predictions) {
        predictions.forEach((prediction) => {
          ctx.beginPath();
          ctx.rect(
            prediction.bbox[0],
            prediction.bbox[1],
            prediction.bbox[2],
            prediction.bbox[3]
          );
          ctx.lineWidth = 3;
          ctx.strokeStyle = "red";
          ctx.stroke();
        });
      }

      function queueDetectedObjects(predictions) {
        const objectNames = predictions.map((pred) => pred.class).join(", ");
        if (objectNames && !isSpeaking) {
          currentSpeechQueue.push(`Detected objects: ${objectNames}`);
          speakNextInQueue();
        }
      }

      function speakNextInQueue() {
        if (currentSpeechQueue.length > 0 && !isSpeaking) {
          isSpeaking = true;
          const speech = new SpeechSynthesisUtterance(
            currentSpeechQueue.shift()
          );
          speech.onend = () => {
            isSpeaking = false;
            speakNextInQueue();
          };
          window.speechSynthesis.speak(speech);
        }
      }

      document
        .getElementById("enableObjectDetection")
        .addEventListener("click", () => {
          objectDetectionEnabled = !objectDetectionEnabled;
          const button = document.getElementById("enableObjectDetection");
          button.textContent = objectDetectionEnabled
            ? "Disable Object Detection"
            : "Enable Object Detection";
        });

      setInterval(captureFrame, 1000); // Capture a frame every second
    </script>
  </body>
</html>

