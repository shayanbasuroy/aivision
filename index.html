<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AI Vision for Blind using TensorFlow</title>
    <style>
      body {
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Roboto", "Oxygen", "Ubuntu", "Cantarell", "Fira Sans", "Droid Sans", "Helvetica Neue", sans-serif;
        background-color: #1c1c1e;
        color: #e5e5e5;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        align-items: center;
        min-height: 100vh;
        flex-direction: column;
      }

      .container {
        text-align: center;
        padding: 20px;
        background-color: #2c2c2e;
        border-radius: 10px;
        box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3);
        width: 90%;
        max-width: 800px;
      }

      h1 {
        font-size: 2.5rem;
        color: #ffffff;
      }

      .camera-container {
        position: relative;
        width: 100%;
        height: 100%;
        max-width: 640px;
        margin: 20px 0;
      }

      video,
      canvas {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        border-radius: 10px;
        box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3);
      }

      button {
        background-color: #007aff;
        color: white;
        border: none;
        padding: 12px 20px;
        border-radius: 8px;
        font-size: 16px;
        cursor: pointer;
        margin-top: 20px;
        transition: background-color 0.3s ease;
      }

      button.green {
        background-color: #4caf50;
      }

      button.red {
        background-color: #e53935;
      }

      button:hover {
        opacity: 0.8;
      }

      .output {
        margin-top: 20px;
        text-align: left;
      }

      ul {
        list-style-type: none;
        padding: 0;
      }

      li {
        padding: 5px 0;
      }

      pre {
        white-space: pre-wrap;
        word-wrap: break-word;
        font-size: 1rem;
        color: #e5e5e5;
      }

      @media (max-width: 768px) {
        h1 {
          font-size: 2rem;
        }

        .camera-container {
          max-width: 100%;
        }

        button {
          font-size: 14px;
          padding: 10px 18px;
        }
      }

      @media (max-width: 480px) {
        h1 {
          font-size: 1.5rem;
        }

        .container {
          padding: 15px;
        }
      }
    </style>
  </head>
  <body>
    <div class="container">
      <h1>AI Vision for Blind using TensorFlow</h1>

      <div class="camera-container">
        <video id="video" width="640" height="480" autoplay></video>
        <canvas id="objectDetectionCanvas" width="640" height="480"></canvas>
      </div>

      <button id="enableObjectDetection" class="green">Disable Object Detection</button>
      <button id="enableTextDetection" class="red">Enable Text Detection</button>

      <div class="output">
        <h3>Detected Objects:</h3>
        <ul id="detectedObjects"></ul>
        <h3>Extracted Text:</h3>
        <pre id="extractedText"></pre>
      </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <script src="https://cdn.jsdelivr.net/npm/tesseract.js"></script>
    <script>
      let model;
      let objectDetectionEnabled = true;
      let textDetectionEnabled = false;
      let textDetectionInterval;
      let textQueue = [];
      let lastAnnouncedTime = 0; // Track time of last announcement

      // Load the COCO-SSD model
      cocoSsd
        .load()
        .then((loadedModel) => {
          model = loadedModel;
          console.log("COCO-SSD model loaded successfully.");
          detectObjects();
        })
        .catch((error) => {
          console.error("Error loading COCO-SSD model:", error);
        });

      // Access the device's camera
      const videoElement = document.getElementById("video");
      const objectDetectionCanvas = document.getElementById("objectDetectionCanvas");
      const ctx = objectDetectionCanvas.getContext("2d");

      // Start camera feed
      navigator.mediaDevices
        .getUserMedia({ video: { facingMode: "environment" } })
        .then((stream) => {
          videoElement.srcObject = stream;
          videoElement.play();
          console.log("Camera is ready.");
        })
        .catch((err) => {
          console.error("Error accessing camera:", err);
        });

      // Capture the frame from the video feed
      function captureFrame() {
        ctx.clearRect(0, 0, objectDetectionCanvas.width, objectDetectionCanvas.height);
        ctx.drawImage(videoElement, 0, 0, objectDetectionCanvas.width, objectDetectionCanvas.height);
        if (objectDetectionEnabled) {
          detectObjects();
        }
        if (textDetectionEnabled) {
          recognizeText();
        }
      }

      // Detect objects with COCO-SSD
      async function detectObjects() {
        if (model) {
          const predictions = await model.detect(objectDetectionCanvas);
          displayDetectedObjects(predictions);
          drawDetectedBoxes(predictions);
          if (objectDetectionEnabled) {
            announceDetectedObjects(predictions);
          }
        }
      }

      // Display detected objects
      function displayDetectedObjects(predictions) {
        const detectedObjectsElement = document.getElementById("detectedObjects");
        detectedObjectsElement.innerHTML = ""; // Clear previous objects
        predictions.forEach((prediction) => {
          const li = document.createElement("li");
          li.textContent = `${prediction.class} - ${Math.round(prediction.score * 100)}%`;
          detectedObjectsElement.appendChild(li);
        });
      }

      // Draw bounding boxes around detected objects
      function drawDetectedBoxes(predictions) {
        predictions.forEach((prediction) => {
          ctx.beginPath();
          ctx.rect(
            prediction.bbox[0],
            prediction.bbox[1],
            prediction.bbox[2],
            prediction.bbox[3]
          );
          ctx.lineWidth = 3;
          ctx.strokeStyle = "red";
          ctx.fillStyle = "red";
          ctx.stroke();
          ctx.fillText(
            `${prediction.class} (${Math.round(prediction.score * 100)}%)`,
            prediction.bbox[0],
            prediction.bbox[1] > 10 ? prediction.bbox[1] - 5 : 10
          );
        });
      }

      // Announce detected objects
      function announceDetectedObjects(predictions) {
        if (predictions.length > 0) {
          const objectNames = predictions.map((pred) => pred.class).join(", ");
          const currentTime = new Date().getTime();

          // Only announce if enough time has passed (to prevent flooding the speech)
          if (currentTime - lastAnnouncedTime > 5000) { // 5-second delay
            const speech = new SpeechSynthesisUtterance(
              `Detected objects: ${objectNames}`
            );
            speechSynthesis.speak(speech);
            lastAnnouncedTime = currentTime; // Update last announced time
          }
        }
      }

      // Recognize text using Tesseract.js
      async function recognizeText() {
        try {
          const textElement = document.getElementById("extractedText");
          textElement.textContent = "Recognizing text...";

          const {
            data: { text },
          } = await Tesseract.recognize(objectDetectionCanvas, "eng", {
            logger: (m) => console.log(m),
          });

          textElement.textContent = text;
          textQueue.push(text);
          announceRecognizedText();
        } catch (error) {
          console.error("Error recognizing text:", error);
          document.getElementById("extractedText").textContent =
            "Error recognizing text.";
        }
      }

      // Announce recognized text with 10-second delay between words
      function announceRecognizedText() {
        if (textQueue.length > 0) {
          const text = textQueue.shift();
          let words = text.split(" ");
          let wordIndex = 0;

          // Announce each word with 10-second delay
          textDetectionInterval = setInterval(() => {
            if (wordIndex < words.length) {
              const speech = new SpeechSynthesisUtterance(words[wordIndex]);
              speechSynthesis.speak(speech);
              wordIndex++;
            } else {
              clearInterval(textDetectionInterval); // Stop the interval when all words are spoken
            }
          }, 10000); // 10 seconds delay between words
        }
      }

      // Toggle Object Detection
      document.getElementById("enableObjectDetection").addEventListener("click", () => {
        objectDetectionEnabled = !objectDetectionEnabled;
        const button = document.getElementById("enableObjectDetection");
        if (objectDetectionEnabled) {
          button.textContent = "Disable Object Detection";
          button.classList.remove("red");
          button.classList.add("green");
        } else {
          button.textContent = "Enable Object Detection";
          button.classList.remove("green");
          button.classList.add("red");
        }
      });

      // Toggle Text Detection
      document.getElementById("enableTextDetection").addEventListener("click", () => {
        textDetectionEnabled = !textDetectionEnabled;
        const button = document.getElementById("enableTextDetection");
        if (textDetectionEnabled) {
          button.textContent = "Disable Text Detection";
          button.classList.remove("red");
          button.classList.add("green");
        } else {
          button.textContent = "Enable Text Detection";
          button.classList.remove("green");
          button.classList.add("red");
        }
      });

      // Continuously capture frames
      setInterval(captureFrame, 100); // Capture every 100ms
    </script>
  </body>
</html>

